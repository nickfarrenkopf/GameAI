Train time: 12+ hours

hidde_encode = [2, 2, 3, 3, 4, 4, 4, 4]
        hidde_decode = [4, 4, 4, 3, 3, 2, 2, 1]
        pools_encode = [2, 2, 2, 1, 2, 1, 1, 2]
        pools_decode = [1, 1, 1, 1, 1, 1, 1, 1]
        hidden_dense = [256, 256, 256]
        n_latent = 64
        hidden_encode = [2 ** i for i in hidde_encode]
        hidden_decode = [2 ** i for i in hidde_decode]
        AUTO.new(paths, name, h, w, length=le, patch=5, print_me=True,
                 hidden_encode=hidden_encode, pools_encode=pools_encode,
                 hidden_latent=hidden_dense, n_latent=n_latent,
                 pools_decode=pools_decode, hidden_decode=hidden_decode)


Creating autoencoder network...
 - C:\Users\Nick\Desktop\Ava\Programs\GameAI\Emulator\data\pacman\network\AUTO_pacman_512_512_3_8_3_64
 - input shape: (?, 512, 512, 3)
 - encode: (?, 256, 256, 4)
 - encode: (?, 128, 128, 4)
 - encode: (?, 64, 64, 8)
 - encode: (?, 64, 64, 8)
 - encode: (?, 32, 32, 16)
 - encode: (?, 32, 32, 16)
 - encode: (?, 32, 32, 16)
 - encode: (?, 16, 16, 16)
 - flat: (?, 4096)
 - latent: (?, 64)
 - dense: (?, 256)
 - dense: (?, 256)
 - dense: (?, 256)
 - dense: (?, 256)
 - reshaped: (?, 16, 16, 1)
 - decode: (?, 16, 16, 16)
 - decode: (?, 16, 16, 16)
 - decode: (?, 16, 16, 16)
 - decode: (?, 16, 16, 8)
 - decode: (?, 16, 16, 8)
 - decode: (?, 16, 16, 4)
 - decode: (?, 16, 16, 4)
 - decode: (?, 16, 16, 2)
 - dense: (?, 786432)
 - output: (?, 786432)
Created AUTO_pacman_512_512_3_8_3_64 network in 24.502487897872925

Training on data with iters
Iter 0  Loss 182090.78125  IO 182090.78125  KL 0.00081
Iter 500  Loss 16998.60156  IO 16998.32422  KL 0.34667
Iter 1000  Loss 11557.78027  IO 11557.77734  KL 0.00389
Iter 1500  Loss 9802.73535  IO 9802.73340  KL 0.00105
Iter 2000  Loss 9944.13379  IO 9944.13281  KL 0.00054
Iter 2500  Loss 10322.75098  IO 10322.75000  KL 0.00037
Iter 3000  Loss 9960.20312  IO 9960.20312  KL 0.00027
Iter 3500  Loss 10556.52734  IO 10556.52734  KL 0.00022
Iter 4000  Loss 10065.49512  IO 10065.49512  KL 0.00015
Iter 4500  Loss 11381.65137  IO 11381.65039  KL 0.00013
Iter 5000  Loss 10278.84766  IO 10278.84766  KL 0.00007
Iter 5500  Loss 10176.35742  IO 10176.35742  KL 0.00003
Iter 6000  Loss 10384.83984  IO 10384.83984  KL 0.00003
Iter 6500  Loss 10119.30566  IO 10119.30566  KL 0.00002
Iter 7000  Loss 10400.05469  IO 10400.05469  KL 0.00002
Iter 7500  Loss 11398.43359  IO 11398.43359  KL 0.00003
Iter 8000  Loss 10533.97363  IO 10533.97461  KL 0.00003
Iter 8500  Loss 9801.55664  IO 9801.55566  KL 0.00002
Iter 9000  Loss 10239.11133  IO 10239.11133  KL 0.00002
Iter 9500  Loss 10212.50684  IO 10212.50684  KL 0.00001
Iter 10000  Loss 10365.89258  IO 10365.89258  KL 0.00001
Iter 10500  Loss 10415.70898  IO 10415.70996  KL 0.00001
Iter 11000  Loss 10472.54199  IO 10472.54102  KL 0.00001
Iter 11500  Loss 10042.86914  IO 10042.87109  KL 0.00001
Iter 12000  Loss 10690.77832  IO 10690.77832  KL 0.00001
Iter 12500  Loss 10406.05664  IO 10406.05664  KL 0.00001
Iter 13000  Loss 10829.77148  IO 10829.77246  KL 0.00001
Iter 13500  Loss 10277.46875  IO 10277.46777  KL 0.00000
Iter 14000  Loss 10407.39453  IO 10407.39355  KL 0.00000
Iter 14500  Loss 9961.51562  IO 9961.51465  KL 0.00000
Iter 15000  Loss 10572.45312  IO 10572.45312  KL 0.00000
Iter 15500  Loss 10117.09570  IO 10117.09473  KL 0.00001
Iter 16000  Loss 10808.79297  IO 10808.79297  KL 0.00002
Iter 16500  Loss 10472.62207  IO 10472.62207  KL 0.00000
Iter 17000  Loss 10619.56836  IO 10619.56836  KL 0.00001
Iter 17500  Loss 10983.79395  IO 10983.79492  KL 0.00000